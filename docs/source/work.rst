工作经历
========

第四范式（北京）技术有限公司
----------------------------

工作成长
````````

tcp连接一侧断开一侧保持
:::::::::::::::::::::::

背景
....

在k8s上启动了pod1，提供接口服务，接口服务使用python flask实现，接口内容为调用kubernetes接口得到相关pod的信息并返回，
这一过程比较有时候缓慢需要数十秒，有时候较快在一秒内，返回响应KB量级；
k8s上有另一个pod2，不断向pod1使用python requests通过service_name发送请求，请求间隔30秒，发送直到获得的信息满足某一条件后停止循环；
发现有几个pod2在一段时间内出现问题为可以看到调用接口前的日志但是看不到调用接口成功后的日志，不符合30秒进行一次请求的预期

调试过程
........

查看pod2的日志和信息，没有发现类似于OOM等明显错误

因为pod2上使用的是python写的代码，使用kill -2将会在日志中打印出interrupted的位置，
在pod2内进行kill -2 1后查看日志，发现中断位置为通过socket读取响应body的过程，说明卡在了http请求中

找到另一个存在一样问题的pod2并进入，使用netstat查看tcp连接状况，发现有一条连接处于ESTABLISHED状态，
且pid对应1即主进程，说明tcp连接依然存在，在pod1中使用netstat查看tcp连接状态，无法发现和pod2的tcp连接，初步判定为tcp连接只存在一边的情况

但是k8s的service有ipvs和iptables两种代理模式，默认是iptables，但如果是ipvs代理模式，pod1的tcp连接不是直接与pod2连接，
而是与service cluster ip背后的服务进行的tcp连接，因为pod2的目标地址是service cluster ip，而pod1上看到的源地址是pod2的ip，
所以在pod1无法发现和pod2的tcp连接，也就是在ipvs模式下pod1内看不到pod2的tcp连接不能说明pod1的tcp连接是断开一半的，
对于pod2来说可能还是建立的和service cluster ip的完整tcp连接

由于没有k8s上的高权限，无法确认具体模式，但是即使是ipvs模式，如果pod1断开了tcp连接，pod2的tcp连接也会断开，
如果没有断开则可能对应ipvs相关服务存在网络问题，先不纠结于这个问题

观察到pod2所在node上tcp_keepalive_time为两小时，等待pod2两小时之后观察发现仍然存活，说明tcp连接是处在连接状态的，
同时发现pod1在期间发生了重启，说明pod2的连接相当于单向连接（抛开k8s的service的代理模式）

尝试在本地复现问题，用docker启动两个container，c1和c2，在c1上提供简单的flask服务，但是服务中通过timesleep模拟耗时操作，
在c2上发送请求，通过尝试在c2发送请求的各个过程中结束c1上的服务进程，尝试复现问题，但是得到的都是ConnectionError或者Abort的报错，而不是和问题一样卡住

结合bug发生时的其他事件，有人在bug发生时间附近反应pod1的服务失败，尝试模拟pod1发生断网导致的问题

因为c1、c2是docker内容器，为了断网c1在宿主机上使用 bridge fdb show 结合在c1上使用ip addr上的信息，
定位出c1在宿主机上对应的虚拟网卡，使用ip link set <eth> down/up进行网络的开关模拟，模拟过程为：
1. 在c1上启动服务，2. 在c2上发送请求，3. 在c2接收到请求之前断开c1网络，4. 观察现象，同时在所有操作开始之前使用tcpdump查看tcp包的情况

结果发现c2上的请求呈现出卡住状态，与线上问题一致，并且长时间没有自动断开，使用netstat在c1和c2上观察，发现c2上确实存在tcp连接，
但是同时c1上也存在ESTABLISHED的tcp连接，此时将c1服务中断，发现c1上的tcp连接均关闭，但是c2上的tcp连接未关闭，说明与问题现象相符合

后续测试，中断c1服务、且等到c1上和c2的tcp连接变成FIN1_WAIT再消失后，重新打开c1网络，c2的请求进程报错Connection Abort；
如果没有中断c1服务或者在中断c1服务后重启c1服务再重新打开c1网络或者在和c2的tcp连接显示断开之前恢复网络，c2请求进程仍可以正常完成请求

但是由于pod1重启后ip地址可能发生变化，相当于c1没有发生重启，因此pod2出现卡住状态，与模拟情况符合

因此可以推断是当时网络问题导致的现象，但是网络问题导致的具体故障还需要在节点上进行更多调试，因为没有权限且重要程度不高因此不再深入调试

总结
....

使用http请求尽量加上timeout，防止上述死锁现象发生

python requests on k8s的耗时
::::::::::::::::::::::::::::

背景
....

在k8s上的一个node上启动了pod1，在相同node上启动了pod2，pod1上向pod2上使用python requests发送http请求，body不大，
进行多次上述操作不限定node，耗时差异大

调试过程
........

首先在本地进行多次测试，发现差异不大，排除可以在本地复现的可能

在k8s上进行测试，发现耗时比本地大很多，多次在不同node上测试，发现有差异但是和本地测试结果差异最大

分析代码 + 代码分部计时，依次排除代码中可能的耗时操作，进一步确认耗时操作是requests导致的

在requests库中找到发送请求的主流程，并在主流程中添加计时，观察到merge_environment_settings耗时较多，
进一步在该函数中进行计时和测试的操作并同步分析代码

在分析代码的过程中发现是requests库在这一函数中遍历了所有的环境变量，并根据环境变量进行一定的设置，
观察pod中的环境变量发现pod中环境变量有数千行，
查阅kubernets文档发现这是因为pod中会包含集群上所有service信息的环境变量，而node上有大量使用service的pod

在python代码中进行了数十万次甚至更高量级的requests调用，每次requests都需要遍历数千个环境变量，因此导致速度缓慢

将requests库修改后进行测试，发现耗时显著降低，确认结果

总结
....

1. pod中可能会存在大量的service相关的环境变量，在使用环境变量遍历的操作的时候需要注意
2. python requests库会遍历环境变量，如果需要在k8s的pod上使用python调用http请求需要注意这一问题对于性能的影响

数据库覆盖清空
::::::::::::::

背景
....

有人在代码仓库中不小心修改了cicd用的测试配置文件中数据库连接的字段，修改到了线上环境的账号密码，
导致cicd执行单测时清空了数据库，发现此现象是因为有人反馈页面上的数据不对

解决过程
........

在数据库中查看现有数据，发现都是单测命名方式的数据，查看git提交记录，说明是单测导致的覆盖

第一时间想到使用binlog恢复，因为数据库开启了binlog且格式为row，运维将binlog备份多份，
并且单独在一个环境上启动mysql用备份出来的binlog进行调试和恢复，进入备份机器上，观察最后的几个binlog文件，
grep是否有DROP语句，确认有之后再前几个binlog文件中查看是否有建表语句

通过grep前几个binlog文件能够发现一个建表语句，但是无法查看到其他建表语句，
将所有的binlog均grep后发现仅仅只有此处和单测的建表语句，发现binlog内容不完整

通过查找是否有其他以前的备份地方，发现在一个数据库中有过重要信息的全量备份，虽然有部分信息被修改，
但是保留了丢失的所有重要信息，因此确认方案为使用该数据库的信息加上binlog进行恢复

由于binlog的create语句带有id、update语句仅对修改部分进行修改，所有binlog导出的sql重复执行也不会影响数据的结果，
因此即使binlog和数据库中有重复的信息也不会影响数据的一致性

通过编写脚本，将binlog文件仅导出与线上环境database相关的部分为sql文件，并且将sql文件source到数据库上，观察执行速度，
发现一天无法执行完成，大约需要到第二天上午才能执行完source

source执行完后简单确认数据一致性，确保source没有严重问题，接下来依次按照业务逻辑重置、启动中间件以及服务，最后确认基本流程无误后上线

总结
....

单体数据库架构下，尽可能保存好完整的binlog，进行多处备份，支持的话定期进行数据库数据备份，线上数据库使用的用户删除DROP的权限

实习经历
--------

图形起源（北京）科技有限公司
````````````````````````````

**背景**:

-  大三下学期开学, 确定不读研, 觉得需要开始找个实习先做一下,
   简历根据网上的模板把自己做的几个大作业写到简历里面, 定位是前端工程师
-  通过猎聘投了若干家公司, 图形起源最早有了回信, 其他的好像也没有回信,
   第一次线上笔试, 内容从java基础到计算机网络到算法,
   除了算法其他大部分都不会, 以为寄了, 不过因为当时给自己定位是前端,
   觉得这投的岗位都错了, 寄了就寄了, 不过hr问我能不能做后端, 我也接了;
   后来面试邀约, 到线下参与面试, 面试主要是聊天, 没有技术向,
   其实就是确定我会去实习
-  当时CTOldx恰好是大一届的计算机系的学长,
   他从初中开始就接触后端工程、电路等相关内容

**收获**:

-  了解了yjs框架, 了解了leveldb和mongodb
-  学会基本使用springboot写crud, 用mybatisplus写查询等,
   了解了mysql基本概念
-  300/d

**工作内容**:

-  用yjs的开源nodejs代码, 结合当时场景的需求, 开发协同后端系统,
   并将原本leveldb改为mongodb
-  用springboot编写一些crud

北京链生科技有限公司
````````````````````

**背景**:

-  暑假生产实习要求时长结束, 感觉在图形起源学不到什么东西了, 辞职
-  恰好收到同班同学jyj邀请, 次日和ldx一起前往朝阳区做一个1k一天的外快,
   包接送, 工作内容是帮助修复bug
-  上午了解情况以及聊天, 因为邀请也是清华学长, 做的是区块链相关,
   下午查看代码加不知所措加无所事事, 涉及到事务、网络等问题, 未了解过,
   摆烂
-  晚上开始讨论真实目的, 邀请过来为了让ldx跳槽带项目, 一开始提了一嘴我,
   但我自己拒绝加当时决定过几天回家加老板觉得不是很好,
   后来吃饭确认拉入ldx
-  由于是最后一个暑假, 选择回家, 开学后受ldx邀请来实习,
   一开始因为工程用golang有些拒绝, 后来看薪资加觉得不实习太闲加赚点外快,
   索性接受

**收获**:

-  了解了golang, gin框架, gorm框架, crud的方式
-  由于gin框架按固定的文件目录格式, router、handler、logic,
   编写了自动生成代码的脚本, 自动生成相同格式部分的代码
-  500/d

**工作内容**:

-  之前项目代码用的php, 在了解项目的基础上用go转写部分

北京云可科技有限公司
````````````````````

**背景**:

-  jyj找到我, 邀请我去avar, 声称是带领开发团队,
   一开始觉得自己能力不足有点不好意思, 接受后面试邀约
-  了解到avar老板是hyt, 面试主要是希望我去做后端开发,
   其实与团队带领没有关系, 因工资较高,
   感觉在链生做也只会做crud并且通勤时间长, 接受

**收获**:

-  服务器指令能力显著增强
-  了解nginx的基本使用方式
-  重拾python anaconda的环境配置, python的运行代码能力
-  学会用阿里云服务器、aws服务器,
   配置安全组、配置阿里云项目管理、阿里云流水线、域名配置、阿里云短信服务配置、阿里云控制访问
-  700/d

**工作内容**:

-  因为当时对java仍然有执念, 用springboot弄了简单的后端,
   crud以及主要是文件的处理以及静态资源的控制
-  运维相关工作, 因为当时我比较节省, 在服务器上装了docker的mysql和redis,
   配置nginx, 配置静态资源, 配置阿里云项目, 配置阿里云流水线
-  使用autodl、gpushare上的gpu跑模型训练,
   用stablediffusion等aigc开源模型,
   后将各种github上的代码利用huggingface带有的统一sdk实现
-  使用aws的ec2
